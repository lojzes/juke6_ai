{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6cca03-004b-41db-b1b3-bf5e0b1830c4",
   "metadata": {},
   "source": [
    "# 第4章 LlamaIndex知识管理与信息检索\n",
    "\n",
    "# 学习目标\n",
    "\n",
    "1. 掌握 LlamalIndex 的特点和基本用法  \n",
    "2. 掌握 LlamalIndex 内置的工具  \n",
    "3. 如何用好SDK简化基于LLM的应用开发\n",
    "\n",
    "1. 大语言模型开发框架的价值是什么？\n",
    "\n",
    "SDK：Software Development Kit，它是一组软件工具和资源的集合，旨在帮助开发者创建、测试、部署和维护应用程序或软件。\n",
    "\n",
    "所有开发框架（SDK）的核心价值，都是降低开发、维护成本。\n",
    "\n",
    "大语言模型开发框架的价值，是让开发者可以更方便地开发基于大语言模型的应用。主要提供两类帮助：\n",
    "\n",
    "1. 第三方能力抽象。比如LLM、向量数据库、搜索接口等  \n",
    "2. 常用工具、方案封装  \n",
    "3.底层实现封装。比如流式接口、超时重连、异步与并行等\n",
    "\n",
    "好的开发框架，需要具备以下特点：\n",
    "\n",
    "1. 可靠性、鲁棒性高  \n",
    "2. 可维护性高  \n",
    "3. 可扩展性高  \n",
    "4. 学习成本低\n",
    "\n",
    "举些通俗的例子：\n",
    "\n",
    "- 与外部功能解依赖\n",
    "\n",
    "比如可以随意更换LLM而不用大量重构代码  \n",
    "- 更换三方工具也同理\n",
    "\n",
    "- 经常变的部分要在外部维护而不是放在代码里\n",
    "\n",
    "比如 Prompt 模板\n",
    "\n",
    "- 各种环境下都适用\n",
    "\n",
    "比如线程安全\n",
    "\n",
    "- 方便调试和测试\n",
    "\n",
    "- 至少要能感觉到用了比不用方便吧  \n",
    "- 合法的输入不会引发框架内部的报错\n",
    "\n",
    "划重点：选对了框架，事半功倍；反之，事倍功半。\n",
    "\n",
    "什么是SDK? https://aws.amazon.com/cn/what-is/sdk/\n",
    "\n",
    "SDK和API的区别是什么？https://aws.amazon.com/cn/compare/the-difference-between-sdk-and-api/\n",
    " \n",
    "# 举个例子：使用SDK，4行代码实现一个简易的RAG系统\n",
    "\n",
    "LlamaIndex默认的Embedding模型是\n",
    "\n",
    "OpenAIEmbedding(model=\"text-embedding-adad002\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527b3c13-3967-4e9e-bd52-e70f61353f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install llama-index \n",
    "#! llama-index-llms-dashscope \n",
    "#! llama-index-llms-openai-like \n",
    "#! llama-index-embeddings-dashscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed2eb7a-6ec8-4e58-b8b0-3e9c4970a51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 22:18:26,565 - WARNING - Ignoring wrong pointing object 235 0 (offset 0)\n",
      "2025-12-08 22:18:26,567 - WARNING - Ignoring wrong pointing object 236 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph 是一个用于构建有状态的多参与者应用程序的库，它利用 LLM（语言模型）来创建代理和多代理工作流。与其它 LLM 框架相比，LangGraph 提供了循环性、可控性和持久性的核心优势。它允许定义包含循环的流程，这对于大多数代理架构来说是必要的，并且提供了对应用流程和状态的细粒度控制。此外，LangGraph 支持自动保存状态以及暂停和恢复图执行的功能，这有助于错误恢复、“人机交互”工作流等场景。该框架还支持在每个节点产生输出时进行流式传输。简而言之，LangGraph 通过将代理工作流建模为图的方式，提供了一种强大而灵活的方法来开发复杂的语言代理应用。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.dashscope import DashScope,DashScopeGenerationModels\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding,DashScopeTextEmbeddingModels\n",
    "from llama_index.core import  VectorStoreIndex,SimpleDirectoryReader\n",
    "\n",
    "llm = DashScope(\n",
    "    model_name=DashScopeGenerationModels.QWEN_MAX,\n",
    "    api_key=\"sk-66bc27a6330f434f8751f8172a73064f\"\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "\n",
    "embedding = DashScopeEmbedding(\n",
    "    model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V1,\n",
    "    api_key=\"sk-66bc27a6330f434f8751f8172a73064f\"\n",
    ")\n",
    "Settings.embed_model = embedding\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"什么是 LangGraph\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a66c3-3d6f-4ad1-bb67-3bbf9bf925a6",
   "metadata": {},
   "source": [
    "# 2. LlamalIndex 介绍\n",
    "\n",
    "官网标题：「Build AI Knowledge Assistants over your enterprise data」\n",
    "\n",
    "- LlamaIndex 是一个为开发「知识增强」的大语言模型应用的框架（也就是 SDK）。知识增强，泛指任何在私有或特定领域数据基础上应用大语言模型的情况。例如：\n",
    "\n",
    "\n",
    "![](./img/1.png)\n",
    "\n",
    "# - Question-Answering Chatbots (也就是 RAG)\n",
    "\n",
    "- Document Understanding and Extraction (文档理解与信息抽取)  \n",
    "- Autonomous Agents that can perform research and take actions (智能体应用)  \n",
    "- Workflow orchestrating single and multi-agent (编排单个或多个智能体形成工作流)\n",
    "- LlamalIndex 有 Python 和 Typescript 两个版本, Python 版的文档相对更完善。  \n",
    "- Python 文档地址: https://docs.llamaindex.ai/en/stable/  \n",
    "- Python API 接口文档: https://docs.llamaindex.ai/en/stable/api.Reference/  \n",
    "- TS 文档地址: https://ts.llamaindex.ai/\n",
    "\n",
    "![](./img/2.png)\n",
    "\n",
    "\n",
    "# 3.数据加载（Loading）\n",
    "\n",
    "# 3.1、加载本地数据\n",
    "\n",
    "SimpleDirectoryReader 是一个简单的本地文件加载器。它会遍历指定目录，并根据文件扩展名自动加载文件（文本内容）。\n",
    "\n",
    "支持的文件类型：\n",
    "\n",
    "```txt\n",
    ".csv - comma-separated values   \n",
    ".docx - Microsoft Word   \n",
    ".epub - EPUB ebook format   \n",
    ".hwp - Hangul Word Processor   \n",
    ".ipynb - Jupyter Notebook   \n",
    ".jpeg, .jpg - JPEG image   \n",
    ".mbox - MBOX email archive   \n",
    ".md - Markdown   \n",
    ".mp3, .mp4 - audio and video   \n",
    ".pdf - Portable Document Format   \n",
    ".png - Portable Network Graphics   \n",
    ".ppt, .pptm, .pptx - Microsoft PowerPoint\n",
    "```\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec45b9d-5f54-4496-a1fe-8bb032f67a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from reprlib import recursive_repr\n",
    "from pydantic import BaseModel\n",
    "from test1 import documents\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "def show_json(data):\n",
    "    \"\"\"\n",
    "    用于展示 json 数据\n",
    "    \"\"\"\n",
    "    if isinstance(data, str):\n",
    "        obj = json.loads(data)\n",
    "        print(json.dumps(obj, indent=4,ensure_ascii=False))\n",
    "    elif isinstance(data, dict):\n",
    "        print(json.dumps(data, indent=4, ensure_ascii=False))\n",
    "    elif issubclass(type(data), BaseModel):\n",
    "        print(json.dumps(data.dict, indent=4, ensure_ascii=False))\n",
    "\n",
    "def show_list_obj(data):\n",
    "    \"\"\"\n",
    "     用于展示一组对象\n",
    "    \"\"\"\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "           show_list_obj(data)\n",
    "    else:\n",
    "        raise ValueError(\"Input is not a list\")\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=\"./data\",\n",
    "    recursive=True,\n",
    "    required_exts=[\".pdf\"]\n",
    ")\n",
    "documents = reader.load_data()\n",
    "\n",
    "print(documents[0].text)\n",
    "show_json(documents[0].json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892dfb0d-285e-487f-b5c7-57a5f4ec2e8f",
   "metadata": {},
   "source": [
    "# 注意：对图像、视频、语音类文件，默认不会自动提取其中文字。如需提取，参考下面介绍的 Data Connectors。\n",
    "\n",
    "默认的PDFReader效果并不理想，我们可以更换文件加载器\n",
    "\n",
    "LlamaParse\n",
    "\n",
    "首先，登录并从https://cloud.llamaindex.ai注册并获取api-key。\n",
    "\n",
    "然后，安装该包：\n",
    "\n",
    "![](./img/3.png)\n",
    "\n",
    "![](./img/4.png)\n",
    "\n",
    "# 4. 文本切分与解析 (Chunking)\n",
    "\n",
    "为方便检索，我们通常把Document切分为Node。\n",
    "\n",
    "在 LlamalIndex 中，Node 被定义为一个文本的「chunk」。\n",
    "\n",
    "# 4.1、使用 TextSplitters 对文本做切分\n",
    "\n",
    "例如：TokenTextSplitter 按指定 token 数切分文本\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc7a81-5226-4079-b7ee-092343f80440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "node_parser = TokenTextSplitter(\n",
    "    chunk_size=512,#每个 chunk 的最大长度\n",
    "    chunk_overlap=200# chunk 之间重叠长度\n",
    ")\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(documents,show_progress=True)\n",
    "\n",
    "show_json(nodes[1].json())\n",
    "show_json(nodes[2].json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d30e6-b63f-4ea5-8c9b-018cb6fc9b6b",
   "metadata": {},
   "source": [
    "# LlamaIndex 提供了丰富的 TextSplitter，例如：\n",
    "\n",
    "- SentenceSplitter：在切分指定长度的 chunk 同时尽量保证句子边界不被切断；(用的最多)  \n",
    "- CodeSplitter：根据 AST（编译器的抽象句法树）切分代码，保证代码功能片段完整；  \n",
    "- SemanticSplitterNodeParser：根据语义相关性对将文本切分为片段。\n",
    "\n",
    "\n",
    "![](./img/5.png)\n",
    "\n",
    "# 5. 索引（Indexing）与检索（Retrieval）\n",
    "\n",
    "基础概念：在「检索」相关的上下文中，「索引」即 index，通常是指为了实现快速检索而设计的特定「数据结构」。\n",
    "\n",
    "索引的具体原理与实现不是本课程的教学重点, 感兴趣的同学可以参考: 传统索引、向量索引\n",
    "\n",
    "# 5.1、向量检索\n",
    "\n",
    "1. VectorStoreIndex 直接在内存中构建一个 Vector Store 并建索引\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efc434d-db9c-4bba-8486-24b216062192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 23:09:04,994 - WARNING - Ignoring wrong pointing object 235 0 (offset 0)\n",
      "2025-12-08 23:09:04,995 - WARNING - Ignoring wrong pointing object 236 0 (offset 0)\n",
      "Parsing nodes: 100%|█████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 315.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph 应用程序的开发、部署、调试和监控： LangGraph 服务器（ API）、 \n",
      "LangGraph SDK（ API 客户端）、 LangGraph CLI（构建服务器的命令行工具）、 LangGraph \n",
      "Studio（用户界面 /调试器）。 \n",
      "主要功能  \n",
      "循环和分支 ：在您的应用程序中实现循环和条件语句。 \n",
      "持久性 ：在图中的每个步骤之后自动保存状态。在任何时候暂停和恢复图执行以支持错误恢复、 \n",
      "“人机交互 ”工作流、时间旅行等等。 \n",
      "“人机交互 ”：中断图执行以批准或编辑代理计划的下一个动作。 \n",
      "流支持 ：在每个节点产生输出时流式传输输出（包括令牌流式传输）。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from reprlib import recursive_repr\n",
    "\n",
    "from llama_index.core.base.embeddings.base import similarity\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from openai import vector_stores\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from test1 import documents\n",
    "\n",
    "\n",
    "def show_json(data):\n",
    "    \"\"\"\n",
    "    用于展示 json 数据\n",
    "    \"\"\"\n",
    "    if isinstance(data, str):\n",
    "        obj = json.loads(data)\n",
    "        print(json.dumps(obj, indent=4,ensure_ascii=False))\n",
    "    elif isinstance(data, dict):\n",
    "        print(json.dumps(data, indent=4, ensure_ascii=False))\n",
    "    elif issubclass(type(data), BaseModel):\n",
    "        print(json.dumps(data.dict, indent=4, ensure_ascii=False))\n",
    "\n",
    "def show_list_obj(data):\n",
    "    \"\"\"\n",
    "     用于展示一组对象\n",
    "    \"\"\"\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "           show_list_obj(data)\n",
    "    else:\n",
    "        raise ValueError(\"Input is not a list\")\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=\"./data\",\n",
    "    recursive=True,\n",
    "    required_exts=[\".pdf\"]\n",
    ")\n",
    "documents = reader.load_data()\n",
    "\n",
    "node_parser = TokenTextSplitter(\n",
    "    chunk_size=512,chunk_overlap=200\n",
    ")\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(documents,show_progress=True)\n",
    "\n",
    "# 构建 index 默认是在内存中\n",
    "index = VectorStoreIndex(nodes)\n",
    "\n",
    "vector_retriver = index.as_retriever(\n",
    "     similarity_top_k = 2\n",
    ")\n",
    "# 检索\n",
    "result = vector_retriver.retrieve(\"LangGraph是什么\")\n",
    "\n",
    "print(result[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d295f03-aa58-4c85-9cc4-35d269cc58f2",
   "metadata": {},
   "source": [
    "![](./img/5.png)\n",
    "\n",
    "# 5.2、更多索引与检索方式\n",
    "\n",
    "LlamaIndex 内置了丰富的检索机制，例如：\n",
    "\n",
    "- 关键字检索\n",
    "\n",
    "- BM25Retriever：基于tokenizer实现的BM25经典检索算法  \n",
    "- KeywordTableGPTRetriever：使用GPT提取检索关键字  \n",
    "- KeywordTableSimpleRetriever：使用正则表达式提取检索关键字  \n",
    "- KeywordTableRAKERetriever：使用RAKE算法提取检索关键字（有语言限制）\n",
    "\n",
    "- RAG-Fusion QueryFusionRetriever  \n",
    "- 还支持 KnowledgeGraph、SQL、Text-to-SQL 等等\n",
    "\n",
    "# 5.3、检索后处理\n",
    "\n",
    "LlamaIndex 的 Node Postprocessors 提供了一系列检索后处理模块。\n",
    "\n",
    "例如：我们可以用不同模型对检索后的 Nodes 做重排序\n",
    "\n",
    "\n",
    "![](./img/7.png)\n",
    "\n",
    "![](./img/8.png)\n",
    "\n",
    "![](./img/9.png)\n",
    "\n",
    "![](./img/10.png)\n",
    "\n",
    "\n",
    "# 7. 底层接口：Prompt、LLM与Embedding\n",
    "\n",
    "# 7.1 Prompt模板\n",
    "\n",
    "PromptTemplate 定义提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87e10364-f822-437a-b66f-b12ecf65d0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'写一个关于小米的笑话'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate('写一个关于{topic}的笑话')\n",
    "\n",
    "prompt.format(topic=\"小米\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150c9e8-2f91-4004-bc40-b52f0da615b3",
   "metadata": {},
   "source": [
    "# ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db75b9e2-d4d1-4743-ae79-5c6c07c5156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: 你叫小明,你必须根据用户提供的上下文回答问题\n",
      "user: 已知上下文: \n",
      "这是一个测试\n",
      "\n",
      "问题:LangGraph 是什么\n",
      "assistant: \n"
     ]
    }
   ],
   "source": [
    "from  llama_index.core.llms import ChatMessage,MessageRole\n",
    "from  llama_index.core import ChatPromptTemplate\n",
    "\n",
    "chat_text_qa_msgs = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=\"你叫{name},你必须根据用户提供的上下文回答问题\",\n",
    "    ),\n",
    "     ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=(\n",
    "            \"已知上下文: \\n\"\\\n",
    "            \"{context}\\n\\n\"\\\n",
    "            \"问题:{question}\"\n",
    "        )\n",
    "    ),\n",
    "]\n",
    "\n",
    "text_qa_template = ChatPromptTemplate(chat_text_qa_msgs)\n",
    "\n",
    "print(\n",
    "    text_qa_template.format(\n",
    "        name=\"小明\",\n",
    "        context=\"这是一个测试\",\n",
    "        question=\"LangGraph 是什么\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0d8e2-bf10-4271-b524-1598797b0efc",
   "metadata": {},
   "source": [
    "![](./img/11.png)\n",
    "\n",
    "![](./img/12.png)\n",
    "\n",
    "![](./img/13.png)\n",
    "\n",
    "\n",
    "# 8. 基于 LlamaIndex 实现一个功能较完整的 RAG 系统\n",
    "\n",
    "# 功能要求：\n",
    "\n",
    "加载指定目录的文件  \n",
    "- 支持 RAG-Fusion  \n",
    "- 使用 Qdrant 向量数据库，并持久化到本地  \n",
    "- 支持检索后排序  \n",
    "- 支持多轮对话\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd36c3e6-e443-426f-abe9-041c33123d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U qdrant_client \n",
    "# !pip install llama-index-vector-stores-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e22c4-e9bd-4092-a3a0-b2b98f845ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types import Embedding\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams,Distance\n",
    "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader,get_response_synthesizer\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.postprocessor import LLMRerank,SimilarityPostprocessor\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.chat_engine import CondenseQuestionChatEngine\n",
    "from llama_index.llms.dashscope import DashScope,DashScopeGenerationModels\n",
    "from llama_index.embeddings.dashscope import DashScopeEmbedding,DashScopeTextEmbeddingModels\n",
    "\n",
    "EMBEDDING_DIM=1536\n",
    "COLLECTION_NAME=\"full_demo\"\n",
    "PATH=\"./qdrant_db\"\n",
    "\n",
    "client = QdrantClient(path=PATH)\n",
    "\n",
    "\n",
    "llm = DashScope(\n",
    "    model_name=DashScopeGenerationModels.QWEN_MAX,\n",
    "    api_key=\"sk-66bc27a6330f434f8751f8172a73064f\"\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "\n",
    "embedding = DashScopeEmbedding(\n",
    "    model_name=DashScopeTextEmbeddingModels.TEXT_EMBEDDING_V1,\n",
    "    api_key=\"sk-66bc27a6330f434f8751f8172a73064f\"\n",
    ")\n",
    "Settings.embed_model = embedding\n",
    "\n",
    "# 2 指定全局文档处理的 Ingestion Pipeline\n",
    "Settings.transformations = [SentenceSplitter(chunk_size=512,chunk_overlap=200)]\n",
    "# 3 加载本地文档\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "\n",
    "if client.collection_exists(collection_name=COLLECTION_NAME):\n",
    "    client.delete_collection(collection_name=COLLECTION_NAME)\n",
    "\n",
    "# 4 创建 collection\n",
    "client.create_collection(COLLECTION_NAME,\n",
    "                         vectors_config=VectorParams(\n",
    "                           size=EMBEDDING_DIM,distance=Distance.COSINE\n",
    "                         )\n",
    "                )\n",
    "\n",
    "# 5 创建 Vector Store\n",
    "vectore_store = QdrantVectorStore(\n",
    "    client=client,collection_name=COLLECTION_NAME,\n",
    ")\n",
    "# 6 指定 Vectore Store 的 Store用于 index\n",
    "storage_context = StorageContext.from_defaults(vector_store=vectore_store)\n",
    "index = VectorStoreIndex.from_documents(documents,storage_context=storage_context)\n",
    "\n",
    "# 7定义检索后排序模型\n",
    "reranker = LLMRerank(top_n=2)\n",
    "# 最终打分低于 0.6的文档被过滤掉\n",
    "sp = SimilarityPostprocessor(similarity_cutoff=0.6)\n",
    "\n",
    "# 8 定义 Rag fusion 检索器\n",
    "fusion_retriever = QueryFusionRetriever(\n",
    "    [index.as_retriever()],\n",
    "    similarity_top_k=5 ,#检索召回 top key 结果\n",
    "    num_queries=3,#生成 query 数\n",
    "    use_async=False,\n",
    "    query_gen_prompt=\"\",#可以自定义 query 生成prompt 模板\n",
    ")\n",
    "\n",
    "# 9 构建单论 query engine\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=fusion_retriever,\n",
    "    node_postprocessors=[reranker],\n",
    "    response_synthesizer=get_response_synthesizer(\n",
    "        response_mode=ResponseMode.REFINE\n",
    "    )\n",
    ")\n",
    "# 10 对话引擎\n",
    "chat_engine = CondenseQuestionChatEngine.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    #condense_question_prompt=\"\",#可自定义 chat message prompt\n",
    ")\n",
    "\n",
    "\n",
    "# 测试多轮对话\n",
    "# User :  LangGraph 是什么\n",
    "while True:\n",
    "    question = input(\"User: \")\n",
    "    if question.strip() == \"e\":\n",
    "        break\n",
    "    response = chat_engine.chat(question)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60511b36-1ff1-4725-9ee0-25b386b07c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
