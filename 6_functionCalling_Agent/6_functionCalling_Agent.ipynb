{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80140d3c-9c3e-42ee-a38c-bfd6d4bfa89b",
   "metadata": {},
   "source": [
    "# 第6章 Function Calling与Agent 智能体\n",
    "\n",
    "# 学习目标\n",
    "\n",
    "1.理解Function Calling的概念  \n",
    "2.理解Function Calling的工作原理  \n",
    "3. 实战使用OpenAI提供的Function Calling接口（基础请求及优化）  \n",
    "4.探讨自定义Function的提供的可能性  \n",
    "5. 探讨Function Calling在大模型应用场景中带来的“质变”  \n",
    "6. 智能体/LLM应用的定义与作用\n",
    "\n",
    "- 什么是智能体？智能体与大模型的关系是什么样的  \n",
    "- 智能体概念的演进过程, 基本架构与功能\n",
    "\n",
    "7. 智能体开发框架smolagents  \n",
    "8. Agentic RAG 实战  \n",
    "9. 智能体的应用场景\n",
    "\n",
    "- 探讨智能体在行业场景中的落地情况  \n",
    "- 探讨智能体系统/LLM应用的常见分类\n",
    "\n",
    "# 1. Function Calling的概念\n",
    "\n",
    "Function Calling (函数调用), 顾名思义, 为模型提供了一种调用函数的方法/能力。\n",
    "\n",
    "- Function Calling成立的模型能力基础：\n",
    "\n",
    "问题理解和行动规划  \n",
    "结构化数据输出  \n",
    "- 上下文学习 In-Context Learning\n",
    "\n",
    "Function Calling让模型输出不再局限于自身推理输出，而是可以与外部系统交互，完成更复杂的任务\n",
    "\n",
    "- 常见Function Calling应用场景包括：\n",
    "\n",
    "- 查询检索，补充额外信息（如RAG、搜索）  \n",
    "- 理解用户输入，向外部系统写入信息（如表单填写）  \n",
    "- 调用外部系统能力，完成实际行动为动作（如下订单）\n",
    "\n",
    "# 2. Function Calling的工作原理\n",
    "\n",
    "# 2.1 OpenAI官方定义\n",
    "\n",
    "OpenAI官方说明文档：https://platform.openai.com/docs/guides/function-calling\n",
    "\n",
    "# 工具调用流程\n",
    "\n",
    "工具调用是通过 OpenAI API 在应用程序和模型之间进行的多步骤对话。工具调用流程包含五个高级步骤：\n",
    "\n",
    "1. 使用模型可以调用的工具向模型发出请求  \n",
    "2. 接收来自模型的工具调用  \n",
    "3. 使用工具调用的输入在应用程序端执行代码  \n",
    "4. 使用工具输出向模型发出第二个请求  \n",
    "5. 接收来自模型的最终响应（或更多工具调用）\n",
    "\n",
    "\n",
    "![](./img/1.png)\n",
    "\n",
    "![](./img/2.png)\n",
    "\n",
    "# 2.3 Calling是结果，理解和选择才是第一步\n",
    "\n",
    "- 除了代表用户诉求的Prompt之外，Function Calling还需要将可用的工具信息（Function Definitions）也提供给模型  \n",
    "在第一次请求时，模型的核心工作如下：\n",
    "\n",
    "1. 理解Prompt所代表的“诉求”和Definitions所代表的“行动可能性”  \n",
    "2. “选择”完成“诉求”所需要进行的“行动”（从“行动可能性”中获得）  \n",
    "3. 根据所选择的“行动”，给出执行“行动”所需的“行动参数”（Parameters）\n",
    "\n",
    "- 那么想一想：\n",
    "\n",
    "1. 什么影响“选择”的效果？  \n",
    "2. 什么影响“行动”的可执行性和效果？\n",
    "\n",
    "\n",
    "# 2.4 作为可选项的结果回调和最终回复输出\n",
    "\n",
    "- 在对话流中, 将Function Calling的结果 (Function Result) 与初始的Prompt诉求再次组合, 提供给模型以获得最终的回复输出, 是常见的流程 (RAG就是一个典型的例子)  \n",
    "- 但如果我们将Function Calling用于非对话流场景，最终回复输出就不一定是必选项了，例如：\n",
    "\n",
    "1.【只需要完成Calling动作】我们只是希望通过Function Calling完成行动选择和发起，接下来就进入业务处理流程，例如：理解用户表达并代替用户下单  \n",
    "2.【只需要完成行动参数Parameters生成】我们只是希望将Function Calling做好工具使用决策，并完成部分请求参数的生成，接下来需要走业务流程补全其他参数（比如鉴权信息），例如：敏感数据查询\n",
    "\n",
    "在实际生产中，不给出最终回复输出，而只是使用Function Calling返回的调用方法数据，是很常见的用法。\n",
    "\n",
    "# 3 实际调用Function Calling\n",
    "\n",
    "## 从官方案例开始\n",
    "\n",
    "## 第一步 工具决策与调用信息生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de09bd22-1885-4e71-ad22-93ccc8f68f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function(arguments='{\"latitude\": 31.2304, \"longlitude\": 121.4737}', name='get_weather')\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-66bc27a6330f434f8751f8172a73064f\",\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "# 工具定义\n",
    "tools = [\n",
    "    {\n",
    "        #类型(固定格式)\n",
    "        \"type\":\"function\",\n",
    "        # 函数定义\n",
    "        \"function\":{\n",
    "            # 函数名称(帮助我们去查找本地的函数在哪里，函数映射的ID)\n",
    "            \"name\":\"get_weather\",\n",
    "            #函数描述(帮助模型理解函数的作用，适用场景，可以理解为Prompt的一部分)\n",
    "            \"description\":\"获取提供坐标的当前温度(摄氏度)\",\n",
    "            # 函数依赖的参数的定义(帮助模型理解如果要做参数生成，应该怎么生成)\n",
    "            \"parameters\":{\n",
    "                #参数形式\n",
    "                \"type\":\"object\",# 对应输出JSON string\n",
    "                # 参数结构\n",
    "                \"properties\":{\n",
    "                    #参数名称\n",
    "                    \"latitude\":{\"type\":\"number\"},\n",
    "                    \"longlitude\":{\"type\":\"number\"}\n",
    "                },\n",
    "                      #必须保证生成的参数列表\n",
    "            \"required\":[\"latitude\",\"longlitude\"],\n",
    "            \"additionalProperties\":False\n",
    "            },\n",
    "            # 格式是否严格\n",
    "            \"strict\":True\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [{\"role\":\"user\",\"content\":\"今天上海的天气怎么样？\"}]\n",
    "#messages = [{\"role\":\"user\",\"content\":\"你今天怎么样？\"}]\n",
    "#messages = [{\"role\":\"user\",\"content\":\"请告诉我北京的经纬度\"}]\n",
    "# messages = [{\"role\":\"user\",\"content\":\"今天天气怎么样？\"}]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "if completion.choices[0].message.tool_calls:\n",
    "    print(completion.choices[0].message.tool_calls[0].function)\n",
    "else:\n",
    "    print(\"没有函数调用\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1833da97-31b0-42a9-94a7-0a13d49c4a1e",
   "metadata": {},
   "source": [
    "## 第二步：时间调用工具\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a9af671-ed0b-460f-96a0-925d8dad9390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call Function Name : get_weather\n",
      "Call Function Arguments : {\"latitude\": 31.2304, \"longlitude\": 121.4737}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "function_calling_message = completion.choices[0].message\n",
    "function_calling = completion.choices[0].message.tool_calls[0]\n",
    "print(\"Call Function Name :\",function_calling.function.name)\n",
    "print(\"Call Function Arguments :\",function_calling.function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6865360f-b53e-484f-b102-e4d40eec49f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temperature': 23, 'weather': '晴天', 'wind_direction': '东南风', 'windy': 2}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_weather(*,latitude:float,longlitude:float):\n",
    "    return {\n",
    "        \"temperature\":23,\n",
    "        \"weather\":\"晴天\",\n",
    "        \"wind_direction\":\"东南风\",\n",
    "        \"windy\":2\n",
    "    }\n",
    "functions = {\n",
    "    \"get_weather\":get_weather\n",
    "}    \n",
    "\n",
    "function_res = functions[function_calling.function.name](**json.loads(function_calling.function.arguments))\n",
    "print(function_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a83be980-2600-4b18-a288-34fb9b4bf0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天上海的天气是晴天，温度为23摄氏度，吹的是东南风，风力为2级。非常适合外出活动！\n"
     ]
    }
   ],
   "source": [
    "# 必须：让模型知道自己之前给了一个什么指令（包含 tool_call_id）\n",
    "\n",
    "messages.append(function_calling_message)\n",
    "# 包含了tool_call_id 的结果加入消息队列\n",
    "messages.append(\n",
    "   {\n",
    "        \"role\":\"tool\",\n",
    "        \"tool_call_id\":function_calling.id,\n",
    "        \"content\":str(function_res)\n",
    "   }\n",
    ")\n",
    "# print(messages)\n",
    "\n",
    "\n",
    "final_res = client.chat.completions.create(\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")\n",
    "# print(fiallnal_res)\n",
    "\n",
    "print(final_res.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f5733-c238-41f4-a85d-918630223ddd",
   "metadata": {},
   "source": [
    "# 调用tools 失败情况下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09549d65-7bc6-428e-b257-7117de69da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-66bc27a6330f434f8751f8172a73064f\",\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "# 工具定义\n",
    "tools = [\n",
    "    {\n",
    "        #类型(固定格式)\n",
    "        \"type\":\"function\",\n",
    "        # 函数定义\n",
    "        \"function\":{\n",
    "            # 函数名称(帮助我们去查找本地的函数在哪里，函数映射的ID)\n",
    "            \"name\":\"get_weather\",\n",
    "            #函数描述(帮助模型理解函数的作用，适用场景，可以理解为Prompt的一部分)\n",
    "            \"description\":\"获取提供坐标的当前温度(摄氏度)\",\n",
    "            # 函数依赖的参数的定义(帮助模型理解如果要做参数生成，应该怎么生成)\n",
    "            \"parameters\":{\n",
    "                #参数形式\n",
    "                \"type\":\"object\",# 对应输出JSON string\n",
    "                # 参数结构\n",
    "                \"properties\":{\n",
    "                    #参数名称\n",
    "                    \"latitude\":{\"type\":\"number\"},\n",
    "                    \"longlitude\":{\"type\":\"number\"}\n",
    "                },\n",
    "                      #必须保证生成的参数列表\n",
    "            \"required\":[\"latitude\",\"longlitude\"],\n",
    "            \"additionalProperties\":False\n",
    "            },\n",
    "            # 格式是否严格\n",
    "            \"strict\":True\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [{\"role\":\"user\",\"content\":\"今天上海的天气怎么样？\"}]\n",
    "#messages = [{\"role\":\"user\",\"content\":\"你今天怎么样？\"}]\n",
    "#messages = [{\"role\":\"user\",\"content\":\"请告诉我北京的经纬度\"}]\n",
    "# messages = [{\"role\":\"user\",\"content\":\"今天天气怎么样？\"}]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "if completion.choices[0].message.tool_calls:\n",
    "    print(completion.choices[0].message.tool_calls[0].function)\n",
    "else:\n",
    "    print(\"没有函数调用\")\n",
    "\n",
    "function_calling_message = completion.choices[0].message\n",
    "function_calling = completion.choices[0].message.tool_calls[0]\n",
    "# print(\"Call Function Name :\",function_calling.function.name)\n",
    "# print(\"Call Function Arguments :\",function_calling.function.arguments)\n",
    "\n",
    "def get_weather(*,latitude:float,longlitude:float):\n",
    "    return {\n",
    "        \"temperature\":23,\n",
    "        \"weather\":\"晴天\",\n",
    "        \"wind_direction\":\"东南风\",\n",
    "        \"windy\":2\n",
    "    }\n",
    "functions = {\n",
    "    \"get_weather\":get_weather\n",
    "}\n",
    "\n",
    "# function_res = functions[function_calling.function.name](**json.loads(function_calling.function.arguments))\n",
    "# 返回错误信息\n",
    "function_res = {\"c\":\"键 'latitude' 已不再支持，请改用 'lat'。\"}\n",
    "# print(function_res)\n",
    "\n",
    "# 必须：让模型知道自己之前给了一个什么指令（包含 tool_call_id）\n",
    "error_messages = messages[:1]\n",
    "error_messages.append(function_calling_message)\n",
    "# 包含了tool_call_id 的结果加入消息队列\n",
    "error_messages.append(\n",
    "   {\n",
    "        \"role\":\"tool\",\n",
    "        \"tool_call_id\":function_calling.id,\n",
    "        \"content\":str(TypeError(function_res))\n",
    "   }\n",
    ")\n",
    "# print(messages)\n",
    "\n",
    "final_res = client.chat.completions.create(\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    messages=error_messages,\n",
    "    tools=tools\n",
    ")\n",
    "# print(final_res)\n",
    "\n",
    "print(final_res.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5c9437-669d-41b3-bb67-c3f6ab72c889",
   "metadata": {},
   "source": [
    "# 4 在实际应用场景中一些案例\n",
    "## 4.1 封装基本方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9fe61086-c2d8-44ea-a0dd-4e5251062ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import  TypedDict\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import ChatCompletionMessageToolCall\n",
    "\n",
    "class FunctionCallingResult(TypedDict):\n",
    "    name: str\n",
    "    arguments: str\n",
    "\n",
    "class ModelRequestWithFunctionCalling:\n",
    "    def __init__(self):\n",
    "        self._client = OpenAI(\n",
    "            api_key=\"sk-66bc27a6330f434f8751f8172a73064f\",\n",
    "            base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "        )\n",
    "        self._function_infos = {}\n",
    "        self._function_mappings = {}\n",
    "        self._messages = []\n",
    "    def register_function(self,*,name,description,parameters,function,**kwargs):\n",
    "        self._function_infos.update(\n",
    "            {\n",
    "                name:{\n",
    "                    \"type\":\"function\",\n",
    "                    \"function\":{\n",
    "                        \"name\":name,\n",
    "                        \"description\":description,\n",
    "                        \"parameters\":parameters,\n",
    "                        **kwargs,\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        self._function_mappings.update({name:function})\n",
    "        return self\n",
    "\n",
    "    def reset_messages(self):\n",
    "        self._messages = []\n",
    "        return self\n",
    "\n",
    "    def append_message(self,role,content,tool_calls=None):\n",
    "        msg = {\n",
    "            \"role\": role,\n",
    "            \"content\": content or \"\",  # 确保content不为None\n",
    "        }\n",
    "        # 仅当tool_calls存在且非空时添加，且转为字典格式\n",
    "        if tool_calls:\n",
    "            msg[\"tool_calls\"] = [self._tool_call_to_dict(tc) for tc in tool_calls]\n",
    "        self._messages.append(msg)\n",
    "        print(\"[Processing Messages]:\", self._messages)\n",
    "        return self\n",
    "    # 辅助方法：将ToolCall对象转为可序列化的字典\n",
    "    def _tool_call_to_dict(self, tool_call: ChatCompletionMessageToolCall) -> dict:\n",
    "        return {\n",
    "            \"id\": tool_call.id,\n",
    "            \"type\": tool_call.type,\n",
    "            \"function\": {\n",
    "                \"name\": tool_call.function.name,\n",
    "                \"arguments\": tool_call.function.arguments,\n",
    "            }\n",
    "        }\n",
    "    def _call(self,function_call_result: FunctionCallingResult):\n",
    "        function = self._function_mappings[function_call_result.name]\n",
    "        arguments = json.loads(function_call_result.arguments)\n",
    "        return function(**arguments)\n",
    "    def request(self,*,role=\"user\",content=None):\n",
    "        if role and content:\n",
    "            self._messages.append({\n",
    "                \"role\":role,\n",
    "                \"content\":content,\n",
    "            })\n",
    "        result = self._client.chat.completions.create(\n",
    "            model=\"qwen3-coder-plus\",\n",
    "            messages=self._messages,\n",
    "            tools=self._function_infos.values()\n",
    "        )\n",
    "        self.append_message(**dict(result.choices[0].message))\n",
    "        if result.choices[0].message.tool_calls:\n",
    "            for tool_call in result.choices[0].message.tool_calls:\n",
    "                call_result = self._call(tool_call.function)\n",
    "                self.append_message(\"tool\",str(call_result),tool_call_id=tool_call.id)\n",
    "                return self.request()\n",
    "        else:\n",
    "            self.append_message(\"assistant\",result.choices[0].message.content)\n",
    "            return result.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f6998-07a1-4234-b203-6cfc25371512",
   "metadata": {},
   "source": [
    "## 4.2 联网检索显示场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b16a2fa1-c3fd-4f76-a30f-a1cb78ac5d90",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ModelRequestWithFunctionCalling.append_message() got an unexpected keyword argument 'refusal'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     33\u001b[39m function_calling_request = ModelRequestWithFunctionCalling()\n\u001b[32m     35\u001b[39m function_calling_request.register_function(\n\u001b[32m     36\u001b[39m         name=\u001b[33m\"\u001b[39m\u001b[33mget_loaction_coordinate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m         description=\u001b[33m\"\u001b[39m\u001b[33m根据 POI 名称,获得 POI的经纬度坐标\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     74\u001b[39m         function=search_nearby_pois,\n\u001b[32m     75\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m result = \u001b[43mfunction_calling_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m五道口附近的咖啡馆\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mModelRequestWithFunctionCalling.request\u001b[39m\u001b[34m(self, role, content)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mself\u001b[39m._messages.append({\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:role,\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m:content,\n\u001b[32m     71\u001b[39m     })\n\u001b[32m     72\u001b[39m result = \u001b[38;5;28mself\u001b[39m._client.chat.completions.create(\n\u001b[32m     73\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mqwen3-coder-plus\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     74\u001b[39m     messages=\u001b[38;5;28mself\u001b[39m._messages,\n\u001b[32m     75\u001b[39m     tools=\u001b[38;5;28mself\u001b[39m._function_infos.values()\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mappend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.choices[\u001b[32m0\u001b[39m].message.tool_calls:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tool_call \u001b[38;5;129;01min\u001b[39;00m result.choices[\u001b[32m0\u001b[39m].message.tool_calls:\n",
      "\u001b[31mTypeError\u001b[39m: ModelRequestWithFunctionCalling.append_message() got an unexpected keyword argument 'refusal'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from typing import  TypedDict\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import ChatCompletionMessageToolCall\n",
    "\n",
    "amap_key = os.getenv(\"Gaode_KEY\")\n",
    "amap_url=\"https://restapi.amap.com/v5\"\n",
    "\n",
    "def get_loaction_coordinate(location,city):\n",
    "    url = f\"{amap_url}/place/text?key={amap_key}&keywords={location}&region={city}\"\n",
    "    r = requests.get(url)\n",
    "    result = r.json()\n",
    "    if \"pois\" in result and result[\"pois\"]:\n",
    "        return result[\"pois\"][0]\n",
    "    return None\n",
    "\n",
    "def search_nearby_pois(longitude,latitude,keyword):\n",
    "    url = f\"{amap_url}/place/around?key={amap_key}&keywords={keyword}&location={longitude},{latitude}\"\n",
    "    r = requests.get(url)\n",
    "    result = r.json()\n",
    "    ans = \"\"\n",
    "    if \"pois\" in result[\"pois\"] and result[\"pois\"]:\n",
    "        for i in range(min(3,len(result[\"pois\"]))):\n",
    "            name = result[\"pois\"][i][\"name\"]\n",
    "            address = result[\"pois\"][i][\"address\"]\n",
    "            distance = result[\"pois\"][i][\"distance\"]\n",
    "            ans += f\"{name}\\n {address}\\n 距离 :{distance}米 \\n\\n\"\n",
    "\n",
    "    return ans\n",
    "\n",
    "function_calling_request = ModelRequestWithFunctionCalling()\n",
    "\n",
    "function_calling_request.register_function(\n",
    "        name=\"get_loaction_coordinate\",\n",
    "        description=\"根据 POI 名称,获得 POI的经纬度坐标\",\n",
    "        parameters={\n",
    "            \"type\":\"object\",\n",
    "            \"properties\":{\n",
    "                \"location\":{\n",
    "                    \"type\":\"string\",\n",
    "                    \"description\":\"POI名称，必须是中文\"\n",
    "                },\n",
    "                \"city\":{\n",
    "                    \"type\":\"string\",\n",
    "                    \"description\":\"POI所在的城市，必须是中文\"\n",
    "                }\n",
    "            },\n",
    "            \"required\":[\"location\",\"city\"]\n",
    "        },\n",
    "        function=get_loaction_coordinate,\n",
    "    ).register_function(\n",
    "        name=\"search_nearby_pois\",\n",
    "        description=\"搜索给定坐标附近的 POI\",\n",
    "        parameters={\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"longitude\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"中心点的经度\"\n",
    "                },\n",
    "                \"latitude\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"中心点的纬度\"\n",
    "                },\n",
    "                \"keyword\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"目标 POI的关键字\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"longitude\", \"latitude\",\"keyword\"]\n",
    "        },\n",
    "        function=search_nearby_pois,\n",
    ")\n",
    "result = function_calling_request.request(content=\"五道口附近的咖啡馆\")\n",
    "print(\"-------------\\n\\n\",result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c340f4-cb59-4afe-b1e6-206ecf9df647",
   "metadata": {},
   "source": [
    "# 4.3 利用文心4.0以上模型作为搜索工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e89423f1-53ca-4243-add9-0e7dd6f5deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据最新信息，2025年12月13日今日头条热搜榜上的新闻涵盖了历史纪念、社会民生、国际冲突、娱乐动态等多个领域，以下是部分热搜新闻的归纳：\n",
      "\n",
      "### 一、历史纪念与国家行动\n",
      "\n",
      "* **南京大屠杀死难者国家公祭日**：2025年12月13日是南京大屠杀死难者国家公祭日，上午10时在侵华日军南京大屠杀遇难同胞纪念馆举行国家公祭仪式，南京全城鸣响防空警报，提醒人们铭记历史、珍爱和平。\n",
      "\n",
      "### 二、社会民生与政策动态\n",
      "\n",
      "* **全国粮食总产量增长**：2025年全国粮食总产量达14298亿斤，比去年增长1.2%，彰显农业稳产保供能力。\n",
      "* **市场监管新规**：国家市场监督管理总局研究起草《汽车行业价格行为合规指南（征求意见稿）》，聚焦新车销售环节，规范明码标价、虚假促销等行为；同时起草《广告引证内容执法指南（征求意见稿）》，回应广告中“销量第一”等违法使用绝对化用语问题。\n",
      "* **北京地铁新线通车**：北京地铁18号线本月底通车，串联天通苑、回龙观与上地软件园，全程仅需约半小时，将有效缓解区域交通压力。\n",
      "* **北京整治网络名人乱象**：北京市网信办启动专项行动，整治网络名人账号煽动对立、宣扬不良价值观等问题，关闭劣迹网红“东北雨姐”“猫一杯”等转世账号。\n",
      "\n",
      "### 三、国际冲突与外交动态\n",
      "\n",
      "* **泰柬边境冲突**：泰国与柬埔寨边境地区爆发冲突，致大量民众撤离，泰国开放临时避难点安置超17万人，国际社会呼吁双方对话缓和局势。\n",
      "* **美日关系动态**：日本被指在台湾问题上配合美国战略，却遭美国加征关税、限制光刻胶出口等反制措施，暴露盟友间利益分歧。\n",
      "\n",
      "### 四、娱乐与文化动态\n",
      "\n",
      "* **短剧《家里家外2》爆红**：该剧上线3天播放量破10亿，连续6天热度值过亿，成为现象级作品，其温情叙事引发全民共情。\n",
      "* **其他娱乐话题**：包括明星动态、影视音乐作品讨论等，如周深演唱的短剧主题曲《时间啊》登上QQ音乐流行指数榜。"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"bce-v3/ALTAK-H6EzzqIaVN5d3ZgeCvf3U/6de527fe81d2b6d37692f296198565368d676db4\",  # 千帆bearer token\n",
    "    base_url=\"https://qianfan.gz.baidubce.com/v2\",  # 千帆域名\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"ernie-4.5-turbo-32k\", # 预置服务请查看模型列表，定制服务请填入API地址\n",
    "    messages=[{'role': 'user', 'content': '今天头条热搜榜有哪些新闻？'}],\n",
    "    stream=True,\n",
    "    extra_body={\n",
    "         \"web_search\":{\n",
    "            \"penalty\":1,\n",
    "            \"enable\":True\n",
    "    }\n",
    "    },\n",
    "    max_completion_tokens=12288,\n",
    "    temperature=0.95,top_p=0.7\n",
    ")\n",
    "\n",
    "#print(completion.choices[0].message.content)\n",
    "\n",
    "for chunk in completion:\n",
    "    if hasattr(chunk.choices[0].delta,\"reasoning_content\") and  chunk.choices[0].delta.reasoning_content:\n",
    "        print(chunk.choices[0].delta.reasoning_content,end=\"\",flush=True)\n",
    "    else:\n",
    "        print(chunk.choices[0].delta.content,end=\"\",flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3ac82-cb60-486b-a4e9-32a042e92725",
   "metadata": {},
   "source": [
    "# 5. Function Calling在大模型应用场景中带来的“质变”\n",
    "\n",
    "知识层面：从模型自身知识（来源于训练语料）扩展到真实世界知识  \n",
    "- 行为层面：从“思考模拟器”、“问题应答”扩展到“理解问题-选择行动-发起请求-理解结果-给出回应”  \n",
    "- 架构层面：让模型不再是一个孤立模块，而是可以融入现有信息系统之中\n",
    "\n",
    "给软件开发思想带来的冲击：\n",
    "\n",
    "- 不是基于“规则”而是基于“世界理解”的调用  \n",
    "- 接纳没有明确的处理过程带来的输出不确定性 (如数据查询)  \n",
    "- 不走极端：“全盘拒绝”和“全盘接受”都不可取\n",
    "\n",
    "\n",
    "# 6. 智能体/LLM应用的定义\n",
    "\n",
    "- Agent智能体的概念存在“过度炒作”的现象，部分媒体使用“智能体”这个词指代任何基于LLM能力构建的应用  \n",
    "- 不给出清晰定义的概念讨论甚至衍生讨论都是耍流氓\n",
    "\n",
    "# 6.1 机器学习概念中的Agent\n",
    "\n",
    "在机器学习领域，智能体（Agent）通常指能够感知环境、做出决策并采取行动以实现特定目标的实体。这些智能体具备自主性，能够通过传感器获取环境信息，经过内部处理后，通过执行器对环境施加影响。这种架构使智能体能够在复杂、多变的环境中自主运作。\n",
    "\n",
    "例如：\n",
    "\n",
    "- Alpha Go  \n",
    "- 星际争霸/Dota 2对战AI  \n",
    "学踢足球的AI点击观看\n",
    "\n",
    "# 6.2 由各类开源项目实践并由Lilian Weng总结的LLM-Powered Autonomous Agents\n",
    "\n",
    "- 原文地址：https://lilianweng.github.io/posts/2023-06-23-agent/  \n",
    "- 重要意义：给基于LLM驱动的智能体讨论提供了共识性的基础定义  \n",
    "- 架构图：\n",
    "\n",
    "\n",
    "![](./img/3.png)\n",
    "\n",
    "\n",
    "# - 核心概念：\n",
    "\n",
    "- 核心驱动：LLM（提供基础智力、通识、逻辑、上下文内学习等基础能力）  \n",
    "- 关键组件：\n",
    "\n",
    "- 规划（Planning）：将复杂任务分解为可管理的子目标（Task Decomposition），并通过自我反思（Self-Reflection）来提高结果质量  \n",
    "。记忆（Memory）：包括短期记忆（对话记录）和长期记忆（通过外部向量存储和快速检索来保留和回忆信息）（这部分突破项目不多，去年有一个叫Mem0的项目刷过一次屏)  \n",
    "。工具使用（Tool Use）：学习调用外部工具，补充额外信息或完成环境交互\n",
    "\n",
    "- Inspiration:\n",
    "\n",
    "- [ReAct论文] (https://arxiv.org/abs/2210.03629)  \n",
    "AutoGPT  \n",
    "GPT-Engineer  \n",
    "BabyAGI\n",
    "\n",
    "\n",
    "# 6.3 多智能体协同\n",
    "\n",
    "- 智能体概念的提出让一批使用类似上述结构（通常是简化的结构，比如只使用Role设定，或是ReAct Prompt）尝试进行多次模型请求协同的项目被关注，核心思想是通过不同的智能体分工协作，组成更大的协作网络  \n",
    "- 代表项目：\n",
    "\n",
    "- Camel.ai  \n",
    "- MetaGPT  \n",
    "- Microsoft AutoGen  \n",
    "- OpenAI Swarm(现在的Agent SDK)\n",
    "- 秒哒（国内）\n",
    "\n",
    "# 7. 智能体开发框架smolagents\n",
    "\n",
    "# 7.1 smolagents 介绍\n",
    "\n",
    "GibHub: https://github.com/huggingface/smolagents\n",
    "\n",
    "官方文档：https://hugging.acce.co/docs/smolagents/index\n",
    "\n",
    "smolagents是HuggingFace官方推出的Agent开发库，构建强大 agent 的最简单框架！。\n",
    "\n",
    "首先来介绍一下smolagents吧，smol是small的俏皮用法，故smolagents的含义是“轻量的agent工具”。smolagents库提供：\n",
    "\n",
    "- 简洁性：Agent逻辑仅需约千行代码。我们将抽象保持在原始代码之上的最小形态！\n",
    "\n",
    "- 支持任何LLM：支持通过Hub托管的模型，使用其transformers版本或通过我们的推理API加载，也支持OpenAI、Anthropic等模型。使用任何LLM为agent提供动力都非常容易。\n",
    "\n",
    "- 一流的代码 agent 支持，即编写代码作为其操作的 agent（与“用于编写代码的 agent”相对），在此了解更多。\n",
    "\n",
    "- Hub 集成：您可以在 Hub 上共享和加载工具，更多功能即将推出！\n",
    "\n",
    "\n",
    "# 8 实战：Agentic RAG\n",
    "\n",
    "# 8.1 传统RAG的局限性\n",
    "\n",
    "尽管传统 RAG 方法有诸多优势,但它也面临一些挑战：\n",
    "\n",
    "1. 单次检索步骤：如果初始检索结果较差,则最终生成的结果将受到影响  \n",
    "2. 查询文档不匹配：用户查询（通常是问题）可能与包含答案（通常是陈述）的文档不太匹配  \n",
    "3. 推理能力有限：简单的 RAG 流程无法进行多步推理或查询细化  \n",
    "4. 上下文窗口约束：检索到的文档必须适合模型的上下文窗口\n",
    "\n",
    "![](./img/4.png)\n",
    "\n",
    "![](./img/5.png)\n",
    "\n",
    "![](./img/6.png)\n",
    "\n",
    "你需要一个有效的 token 作为环境变量 HF_TOKEN 来调用 Inference Providers。\n",
    "\n",
    "Hugging Face注册-登录-创建Access Tokens-系统环境变量配置HF_TOKEN\n",
    "\n",
    "我们首先加载一个知识库以在其上执行 RAG：此数据集是许多 Hugging Face 库的文档页面的汇编，存储为 markdown 格式。我们将仅保留 transformers 库的文档。然后通过处理数据集并将其存储到向量数据库中，为检索器准备知识库。我们将使用 LangChain 来利用其出色的向量数据库工具。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18e275a2-c46f-4f49-92cd-87b2e7c77e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/6_functionCalling_Agent/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import datasets\n",
    "from langchain_core.documents import Document\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_classic.retrievers import BM25Retriever\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")\n",
    "knowledge_base = knowledge_base.filter(lambda row: row[\"source\"].startswith(\"huggingface/transformers\"))\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]}) for doc in knowledge_base\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "docs_processed = text_splitter.split_documents(source_docs)\n",
    "print(docs_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737b80d-ea6e-41ad-be33-8713d4b68f1a",
   "metadata": {},
   "source": [
    "现在文档已准备好。我们来一起构建我们的 agent RAG 系统！我们只需要一个 RetrieverTool，我们的 agent 可以利用它从知识库中检索信息。\n",
    "\n",
    "由于我们需要将 vectordb 添加为工具的属性，我们不能简单地使用带有 @tool 装饰器的简单工具构造函数：因此我们将遵循 tools 教程中突出显示的高级设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67f1375d-f654-4fe5-a547-d113166c6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from smolagents import Tool\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Uses lexical search to retrieve the parts of transformers documentation that could be most relevant to answer your query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be lexically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(docs, k=10)\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.retriever.invoke(\n",
    "            query,\n",
    "        )\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content for i, doc in enumerate(docs)]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299ddf1-ce96-45d4-9f91-cc3fb9e5d29d",
   "metadata": {},
   "source": [
    "BM25 检索方法是一个经典的检索方法，因为它的设置速度非常快。为了提高检索准确性，你可以使用语义搜索，使用文档的向量表\n",
    "示替换 BM25:因此你可以前往 MTEB Leaderboard 选择一个好的嵌入模型。\n",
    "\n",
    "现在我们已经创建了一个可以从知识库中检索信息的工具，现在我们可以很容易地创建一个利用这个 retriever_tool 的 agent！因此 agent 将使用如下参数初始化：\n",
    "\n",
    "- tools：代理将能够调用的工具列表。  \n",
    "- model：为代理提供动力的LLM。\n",
    "\n",
    "我们的 model 必须是一个可调用对象，它接受一个消息的 list 作为输入，并返回文本。它还需要接受一个 stop_sequences 参数数，指示何时停止生成。为了方便起见，我们直接使用包中提供的 HfEngine 类来获取调用 Hugging Face 的 Inference API 的 ALLM 引擎。\n",
    "\n",
    "接着，我们将使用 meta-llama/Llama-3.3-70B-Instruct 作为 llm 引擎，因为：\n",
    "\n",
    "- 它有一个长  $128 \\mathrm{k}$  上下文，这对处理长源文档很有用。  \n",
    "- 它在 HF 的 Inference API 上始终免费提供！\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c8b5055-6294-41c0-b3df-72a8256161d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from smolagents import CodeAgent, InferenceClientModel\n",
    "\n",
    "retriever_tool = RetrieverTool(docs_processed)\n",
    "agent = CodeAgent(\n",
    "    tools=[retriever_tool],\n",
    "    model=InferenceClientModel(model_id=\"Qwen/Qwen3-Next-80B-A3B-Thinking\",api_key=os.getenv(\"HuggingFace_KEY\")),\n",
    "    max_steps=4,\n",
    "    verbosity_level=2,\n",
    "    stream_outputs=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a72b6b-7e3d-4d64-a8f2-6193881d6ca8",
   "metadata": {},
   "source": [
    "当我们初始化 CodeAgent 时，它已经自动获得了一个默认的系统提示，告诉 LLM 引擎按步骤处理并生成工具调用作为代码片段但你可以根据需要替换此提示模板。接着，当其.run()方法被调用时，代理将负责调用 LLM 引擎，并在循环中执行工具调用直到工具 final answer 被调用，而其参数为最终答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3ce03c1-08df-45c1-ad1e-8541e467c0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">For a transformers model training, which is slower, the forward or the backward pass?</span>                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ InferenceClientModel - Qwen/Qwen3-Next-80B-A3B-Thinking ───────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mFor a transformers model training, which is slower, the forward or the backward pass?\u001b[0m                           \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m InferenceClientModel - Qwen/Qwen3-Next-80B-A3B-Thinking \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/anaconda3/envs/6_functionCalling_Agent/lib/python3.11/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/anaconda3/envs/6_functionCalling_Agent/lib/python3.11/site-packages/rich/live.py:256: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">query </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"transformers model training forward backward pass speed comparison\"</span><span style=\"background-color: #272822\">                                   </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">result </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> retriever(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">query)</span><span style=\"background-color: #272822\">                                                                                </span>  \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(result)</span><span style=\"background-color: #272822\">                                                                                                  </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mtransformers model training forward backward pass speed comparison\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mresult\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m  \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresult\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "\n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
       "in \n",
       "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
       "needed \n",
       "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
       "\n",
       "===== Document 1 =====\n",
       "- A train step function which combines the loss function and optimizer update, does the forward and backward pass \n",
       "and returns the updated parameters.\n",
       "\n",
       "===== Document 2 =====\n",
       "overhead. This is super helpful when you have activation checkpointing enabled, where we do a forward recompute and\n",
       "backward passes a single layer granularity and want to keep the parameter in the forward recompute till the \n",
       "backward\n",
       "\n",
       "===== Document 3 =====\n",
       "For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally \n",
       "translates \n",
       "into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually \n",
       "bandwidth-limited, and it’s typical for an activation to have to read more data in the backward than in the forward\n",
       "(e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the \n",
       "forward,\n",
       "\n",
       "===== Document 4 =====\n",
       "becomes possible to increase the **effective batch size** beyond the limitations imposed by the GPU's memory \n",
       "capacity. \n",
       "However, it is important to note that the additional forward and backward passes introduced by gradient \n",
       "accumulation can \n",
       "slow down the training process.\n",
       "\n",
       "===== Document 5 =====\n",
       "## How to benchmark 🤗 Transformers models\n",
       "\n",
       "The classes [`PyTorchBenchmark`] and [`TensorFlowBenchmark`] allow to flexibly benchmark 🤗 Transformers models. \n",
       "The benchmark classes allow us to measure the _peak memory usage_ and _required time_ for both _inference_ and \n",
       "_training_.\n",
       "\n",
       "&lt;Tip&gt;\n",
       "\n",
       "Hereby, _inference_ is defined by a single forward pass, and _training_ is defined by a single forward pass and\n",
       "backward pass.\n",
       "\n",
       "&lt;/Tip&gt;\n",
       "\n",
       "===== Document 6 =====\n",
       "than 10 seconds. In case only very large checkpoints are available,\n",
       "    it might make more sense to create a dummy model in the new\n",
       "    environment with randomly initialized weights and save those weights\n",
       "    for comparison with the 🤗 Transformers version of your model\n",
       "-   Make sure you are using the easiest way of calling a forward pass in\n",
       "    the original repository. Ideally, you want to find the function in\n",
       "    the original repository that **only** calls a single forward pass,\n",
       "\n",
       "===== Document 7 =====\n",
       "than 10 seconds. In case only very large checkpoints are available,\n",
       "    it might make more sense to create a dummy model in the new\n",
       "    environment with randomly initialized weights and save those weights\n",
       "    for comparison with the 🤗 Transformers version of your model\n",
       "-   Make sure you are using the easiest way of calling a forward pass in\n",
       "    the original repository. Ideally, you want to find the function in\n",
       "    the original repository that **only** calls a single forward pass,\n",
       "\n",
       "===== Document 8 =====\n",
       "In case only very large checkpoints are available, it might make more sense to create a dummy model in the new\n",
       "  environment with randomly initialized weights and save those weights for comparison with the 🤗 Transformers \n",
       "version\n",
       "  of your model\n",
       "- Make sure you are using the easiest way of calling a forward pass in the original repository. Ideally, you want \n",
       "to\n",
       "  find the function in the original repository that **only** calls a single forward pass, *i.e.* that is often \n",
       "called\n",
       "\n",
       "===== Document 9 =====\n",
       "```python\n",
       "model = BarkModel.from_pretrained(\"suno/bark-small\", torch_dtype=torch.float16, \n",
       "attn_implementation=\"flash_attention_2\").to(device)\n",
       "```\n",
       "\n",
       "##### Performance comparison\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "\n",
       "Retrieved documents:\n",
       "\n",
       "\n",
       "===== Document 0 =====\n",
       "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
       "in \n",
       "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
       "needed \n",
       "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
       "\n",
       "===== Document 1 =====\n",
       "- A train step function which combines the loss function and optimizer update, does the forward and backward pass \n",
       "and returns the updated parameters.\n",
       "\n",
       "===== Document 2 =====\n",
       "overhead. This is super helpful when you have activation checkpointing enabled, where we do a forward recompute and\n",
       "backward passes a single layer granularity and want to keep the parameter in the forward recompute till the \n",
       "backward\n",
       "\n",
       "===== Document 3 =====\n",
       "For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally \n",
       "translates \n",
       "into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually \n",
       "bandwidth-limited, and it’s typical for an activation to have to read more data in the backward than in the forward\n",
       "(e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the \n",
       "forward,\n",
       "\n",
       "===== Document 4 =====\n",
       "becomes possible to increase the **effective batch size** beyond the limitations imposed by the GPU's memory \n",
       "capacity. \n",
       "However, it is important to note that the additional forward and backward passes introduced by gradient \n",
       "accumulation can \n",
       "slow down the training process.\n",
       "\n",
       "===== Document 5 =====\n",
       "## How to benchmark 🤗 Transformers models\n",
       "\n",
       "The classes [`PyTorchBenchmark`] and [`TensorFlowBenchmark`] allow to flexibly benchmark 🤗 Transformers models. \n",
       "The benchmark classes allow us to measure the _peak memory usage_ and _required time_ for both _inference_ and \n",
       "_training_.\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Hereby, _inference_ is defined by a single forward pass, and _training_ is defined by a single forward pass and\n",
       "backward pass.\n",
       "\n",
       "</Tip>\n",
       "\n",
       "===== Document 6 =====\n",
       "than 10 seconds. In case only very large checkpoints are available,\n",
       "    it might make more sense to create a dummy model in the new\n",
       "    environment with randomly initialized weights and save those weights\n",
       "    for comparison with the 🤗 Transformers version of your model\n",
       "-   Make sure you are using the easiest way of calling a forward pass in\n",
       "    the original repository. Ideally, you want to find the function in\n",
       "    the original repository that **only** calls a single forward pass,\n",
       "\n",
       "===== Document 7 =====\n",
       "than 10 seconds. In case only very large checkpoints are available,\n",
       "    it might make more sense to create a dummy model in the new\n",
       "    environment with randomly initialized weights and save those weights\n",
       "    for comparison with the 🤗 Transformers version of your model\n",
       "-   Make sure you are using the easiest way of calling a forward pass in\n",
       "    the original repository. Ideally, you want to find the function in\n",
       "    the original repository that **only** calls a single forward pass,\n",
       "\n",
       "===== Document 8 =====\n",
       "In case only very large checkpoints are available, it might make more sense to create a dummy model in the new\n",
       "  environment with randomly initialized weights and save those weights for comparison with the 🤗 Transformers \n",
       "version\n",
       "  of your model\n",
       "- Make sure you are using the easiest way of calling a forward pass in the original repository. Ideally, you want \n",
       "to\n",
       "  find the function in the original repository that **only** calls a single forward pass, *i.e.* that is often \n",
       "called\n",
       "\n",
       "===== Document 9 =====\n",
       "```python\n",
       "model = BarkModel.from_pretrained(\"suno/bark-small\", torch_dtype=torch.float16, \n",
       "attn_implementation=\"flash_attention_2\").to(device)\n",
       "```\n",
       "\n",
       "##### Performance comparison\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 9.54 seconds| Input tokens: 2,106 | Output tokens: 807]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 9.54 seconds| Input tokens: 2,106 | Output tokens: 807]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Step 2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1;37mStep 2\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> ─ <span style=\"font-weight: bold\">Executing parsed code:</span> ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"backward\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                       </span>  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n",
       "</pre>\n"
      ],
      "text/plain": [
       " ─ \u001b[1mExecuting parsed code:\u001b[0m ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbackward\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m  \n",
       " ───────────────────────────────────────────────────────────────────────────────────────────────────────────────── \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: backward</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mFinal answer: backward\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 6.05 seconds| Input tokens: 5,149 | Output tokens: 1,290]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 2: Duration 6.05 seconds| Input tokens: 5,149 | Output tokens: 1,290]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "backward\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent_output = agent.run(\"For a transformers model training, which is slower, the forward or the backward pass?\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241c1e5-a976-4842-8ab7-8622c35289f9",
   "metadata": {},
   "source": [
    "# 9. 智能体系统/LLM应用的应用场景\n",
    "\n",
    "# 项目举例：\n",
    "\n",
    "- DeepResearch\n",
    "\n",
    "# 应用场景举例：\n",
    "\n",
    "- 文案生成  \n",
    "- AutoCoder  \n",
    "- NL2DB  \n",
    "- 智能家居  \n",
    "- 智能座舱\n",
    "\n",
    "# 10. 智能体系统/LLM应用核心逻辑的几种分类\n",
    "\n",
    "- CoT/简单工作流  \n",
    "- 附加Function Calling的单次请求  \n",
    "- 基于SOP的复杂工作流  \n",
    "自规划  \n",
    "…\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69f8ad-a077-4c51-a458-b54eeb201ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
